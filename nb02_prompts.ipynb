{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682c4c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb1d276",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0e461e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"llama-3.1-8b-instant\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca18e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "\n",
    "prompt_template = \"\"\"Translate the given text in to the given language: \n",
    "Text: {text}\n",
    "Lang: {lang}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca177aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the given text in to the given language: \n",
      "Text: Who are you?\n",
      "Lang: hindi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(text = \"Who are you?\", lang=\"hindi\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6f93f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The translation of \"Who are you?\" to Hindi is:\\n\\nà¤•à¥Œà¤¨ à¤¹à¥‹? \\n\\n(Kaun ho?)', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 56, 'total_tokens': 80, 'completion_time': 0.032141507, 'prompt_time': 0.078643925, 'queue_time': 0.058511085, 'total_time': 0.110785432}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c40956ddc4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--217fb39b-31bd-44f7-b476-eee532935677-0', usage_metadata={'input_tokens': 56, 'output_tokens': 24, 'total_tokens': 80})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple model call\n",
    "\n",
    "response =  model.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "044667ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translation of \"Who are you?\" to Hindi is:\n",
      "\n",
      "à¤•à¥Œà¤¨ à¤¹à¥‹? \n",
      "\n",
      "(Kaun ho?)\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1d44e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Change the sentence from active voice to passive voice: \n",
    "Text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e3d0b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change the sentence from active voice to passive voice: \n",
      "Text: Reena has a cat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(text = \"Reena has a cat\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b7fa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The sentence \"Reena has a cat\" is already in a somewhat passive voice, as the subject \"Reena\" is not performing an action, but rather receiving or possessing something. \\n\\nHowever, if we rephrase the sentence to emphasize the possession rather than the action, we can make it more passive:\\n\\n- Original sentence: Reena has a cat (active voice)\\n- Passive voice: A cat is owned by Reena.\\n\\nAlternatively, if we want to make it more passive with the original wording, we could rephrase it as:\\n\\n- Passive voice: A cat has been kept by Reena.\\n\\nHowever, the most accurate way to change the sentence to passive voice would be the first example given.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 143, 'prompt_tokens': 54, 'total_tokens': 197, 'completion_time': 0.275314593, 'prompt_time': 0.098607984, 'queue_time': 0.057465236, 'total_time': 0.373922577}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7083106d2c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c4034f2b-e6df-4e57-83c2-f9854f7dc5f4-0', usage_metadata={'input_tokens': 54, 'output_tokens': 143, 'total_tokens': 197})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response =  model.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85ce728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence \"Reena has a cat\" is already in a somewhat passive voice, as the subject \"Reena\" is not performing an action, but rather receiving or possessing something. \n",
      "\n",
      "However, if we rephrase the sentence to emphasize the possession rather than the action, we can make it more passive:\n",
      "\n",
      "- Original sentence: Reena has a cat (active voice)\n",
      "- Passive voice: A cat is owned by Reena.\n",
      "\n",
      "Alternatively, if we want to make it more passive with the original wording, we could rephrase it as:\n",
      "\n",
      "- Passive voice: A cat has been kept by Reena.\n",
      "\n",
      "However, the most accurate way to change the sentence to passive voice would be the first example given.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4fd624",
   "metadata": {},
   "source": [
    "# Exercise: A RAG Prompt (Retreival Augmented Generation)\n",
    "\n",
    "https://smith.langchain.com/hub/rlm/rag-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "959ec4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15482b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajit lives in Greater Noida, which is located in India. Greater Noida is a city in the state of Uttar Pradesh in India.\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(\n",
    "    context = \"Ajit lives in Greater Noida\", \n",
    "    question=\"In which country does Ajit live in?\"\n",
    ")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"llama-3.1-8b-instant\", model_provider=\"groq\")\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aabbd227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise time:\n",
    "\n",
    "# Change the context to your liking\n",
    "# Ask relevanent question to your context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c35ab1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_context = \"\"\"Donald Trump's top economic adviser has warned that if India fails to curb its Russian crude trade, the US President will not ease his stance on Washington's punitive tariffs on Indian imports. US National Economic Council Director Kevin Hassett called trade negotiations with New Delhi \"complicated\", as he accused India of \"intransigence\" in opening its markets to American products. \n",
    "\n",
    "\"If the Indians don't budge, I don't think President Trump will,\" he said. The United States on Wednesday doubled tariffs on Indian goods to a staggering 50 per cent, the highest for any country other than Brazil. This includes a 25 per cent additional duty for India's purchase of Russian crude oil.\n",
    "\n",
    "Add NDTV As A Trusted Source\n",
    "\n",
    "\"Indian Intransigence\" ðŸ¤¯: US Economic Adviser - \"If the Indians Don't Budge, I Don't Think Trump Will Either\"\n",
    "\n",
    "Kevin Hassett seems to think that protecting India's rights and rejecting elements of an FTA that aren't mutually beneficial is INTRANSIGENT - simply India refusing toâ€¦ https://t.co/gBZ3C9DEFS pic.twitter.com/cnWGXmUwAP\n",
    "\n",
    "â€” RT_India (@RT_India_news) August 28, 2025\n",
    "Hassett said trade negotiations with India were \"complicated\", claiming part of it \"has been tied to the pressure we've been trying to put on Russia in order to secure a peace deal and save millions of lives. And then there's the Indian intransigence about opening their markets to our products.\"\n",
    "\n",
    "Linking India-US trade negotiations to a marathon, Hassett said talks require a long-term outlook and acceptance of \"ebbs and flows\" before New Delhi and Washington reach the final position.\n",
    "\n",
    "\n",
    "\"When you look at trade negotiations, one lesson we've all learnt is that you need to keep your eyes on the horizon and recognise that there are going to be ebbs and flows before we reach the final position,\" he said.\n",
    "\n",
    "Team Trump's Tariff Outlook\n",
    "The Trump adviser's remarks echoed US Treasury Secretary Scott Bessent's earlier comments, where he said high tariffs on India are \"not just over India's purchase of Russian oil\" but also due to the protracted nature of the ongoing trade deal talks.\n",
    "\n",
    "\"I'd thought we'd have a deal in May or June; that India could be one of the earliest deals. But they, kind of, tapped us along,\" Bessent told Fox Business on Wednesday. \n",
    "\n",
    "He claimed New Delhi had been \"a bit uncooperative\" during negotiations and said, \"This is a very complicated relationship.\"\n",
    "\n",
    "\"I do think India is the world's largest democracy, and the US is the world's largest economy. I think at the end of the day we will come together,\" he added.\n",
    "\n",
    "India's Stand\n",
    "India has asserted that it is prepared to stand firm against US pressure, with Prime Minister Narendra Modi vowing he would \"never compromise\" the interests of the country's farmers.\n",
    "\n",
    "The government estimates the tariffs will impact $48.2 billion worth of Indian exports to the US. Officials have warned that, though the immediate impact of new duties appears limited, the ripple effects on the economy pose challenges that must be addressed.\n",
    "\n",
    "The new duties could make shipments to the US commercially unviable, triggering job losses and slower economic growth, they said.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1b7af5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The US has imposed punitive tariffs on Indian imports, doubling them to 50% as a result of India's failure to curb its Russian crude trade and open its markets to American products. The tariffs include a 25% additional duty on India's purchase of Russian crude oil, with US officials accusing India of \"intransigence\".\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(\n",
    "    context = news_context, \n",
    "    question=\"Summarize the US Tarrif policy for India\"\n",
    ")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"llama-3.1-8b-instant\", model_provider=\"groq\")\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafde195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: \n",
    "\n",
    "# Copy paste an online blog as a context. \n",
    "# Ask question related to that blog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645eb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise:\n",
    "\n",
    "# How to put \n",
    "# context = content of a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f5706c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To read the context from a file\n",
    "with open(\"Blog.txt\", 'r') as file:\n",
    "    new_context_from_file = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ea863dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kuchipudi is a classical Indian dance form that originated in Andhra Pradesh, India, characterized by intricate footwork, graceful movements, and subtle facial expressions. It incorporates elements of pure dance (Nritta), expressive dance (Nritya), and storytelling through dance (Natya), often drawing from Hindu mythology. Kuchipudi has a rich history dating back to the 3rd century BCE and is recognized as one of the eight classical dance forms of India.\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(\n",
    "    context = new_context_from_file, \n",
    "    question=\"Summarize the text on kuchipudi dance\"\n",
    ")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"llama-3.1-8b-instant\", model_provider=\"groq\")\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
